---
title:          "Galvatron: An Automatic Distributed System for Efficient Foundation Model Training"
date:           2025-01-09 00:00:00 +0800
selected:       false
pub:            "<strong><span style='color: blue'>[Under Review]</span></strong>"
pub_date:       "2025"

abstract: >-
  Galvatron is a distributed system for efficiently training large-scale Foundation Models. It overcomes the complexities of selecting optimal parallelism strategies by automatically identifying the most efficient hybrid strategy, incorporating data, tensor, pipeline, sharded data, and sequence parallelism, along with recomputation. This open-source system offers user-friendly interfaces and comprehensive documentation, making complex distributed training accessible and efficient. Benchmarking on various clusters demonstrates Galvatron's superior throughput compared to existing frameworks.
cover:          /assets/images/covers/Hetu-Galvatron.png
authors:
  - Xinyi Liu*
  - <strong><u>Yujie Wang*</u></strong>
  - Shenhan Zhu*
  - Fangcheng Fu
  - Qingshuo Liu
  - Guangming Lin
  - Bin Cui
links:
  Arxiv: https://arxiv.org/abs/2504.21411
---

