primary_name: "Yujie Wang | 王驭捷"
# secondary_name: "王驭捷"
navbar_name: "Yujie Wang"

positions:
- logo: /assets/images/badges/PKU.png  # Logo is optional
  name: A fourth-year Ph.D. candidate in <a href="https://english.pku.edu.cn/" target="_blank">Peking University (PKU)</a>
# - name: Position 2 without logo


email: "alfredwang@pku.edu.cn"
# cv_link: link-to-your-cv-file
gscholar: nksk9D8AAAAJ  # This is an example, replace it with your own Google Scholar ID
github: AFDWang
# twitter: your_twitter_id  # Do not include the '@' symbol
# wechat_qrcode: /assets/images/etc/wechat.jpg
# wechat_prompt: >-
#   Please tell me your <strong>name</strong> and <strong>affiliation</strong> (current or past) when adding my wechat. Thanks!
# linkedin: your-linked-in-id
orcid: 0009-0000-8375-493X

short_bio_text_justify: false
short_bio: >-
  <p>
    I am a Ph.D. student in the School of Computer Science at <a href="https://english.pku.edu.cn/" target="_blank">Peking University (PKU)</a>, 
    where I have been studying since 2021 under the guidance of <a href="https://cuibinpku.github.io/" target="_blank">Prof. Bin Cui</a>.
    I received my Bachelor's degree from Peking University in 2021.
  </p>
  <p>
    My research interest primarily lies in <strong>Distributed Deep/Machine Learning (DL/ML) Systems, Infrastructure for Large Language Models (LLMs)</strong>.
    Currently, I am focusing on: (1) Parallelism optimization for LLMs; (2) Efficient long-context training; (3) Multi-task, multi-modality training acceleration; 
    (4) Memory management and communication optimization in distributed systems.
    Recently, I have also been exploring (1) Diffusion model training and inference optimization, and (2) Post-training and reinforcement learning techniques.
  </p>
  <p>
    I have published 8 papers in top-tier CCF-A conferences and journals (4 first-authored and 2 second-authored), including ASPLOS, TKDE, ICLR, VLDB, SIGMOD, and SOSP.
    I am the designer, project leader, and main developer of <a href="https://github.com/PKU-DAIR/Hetu-Galvatron" target="_blank">Hetu-Galvatron</a>, 
    an open-source automatic parallel training system optimized for LLMs. 
    Additionally, I am a core developer of <a href="https://github.com/PKU-DAIR/Hetu" target="_blank">Hetu</a>, a high-performance distributed deep learning system. 
    My works and systems has been applied in billion-scale industrial applications, such as accelerating the training of LLMs with over 100B parameters, 
    and has been adopted by companies like HUAWEI, ZTE, Alibaba, and BAAI. 
    Currently, I am also collaborating with more companies to deploy and further develop these systems, such as ByteDance and Baidu.
  </p>

portrait_url: /assets/images/photos/portrait-wyj.jpg
# portrait_caption: >-
#   Photo by Manja Vitolic on Unsplash (this caption is optional, comment it out to disable).

education:
- name: Peking University
  logo: /assets/images/badges/PKU.png
  position: >- 
    School of Computer Science <br/>
    Ph.D. Student
  date: Sep. 2021 - present
- name: Peking University
  logo: /assets/images/badges/PKU.png
  position: B.S. in Computer Science
  date: Sep. 2017 - Jul. 2021

# experience:
# - name: Peking University
#   logo: /assets/images/badges/PKU_red.png
#   position: Research Intern
#   date: Sep. 2019 - Jul. 2021

awards:
- name: Award Name 2
  date: 2024
- name: Award Name 1 
  date: 2021
- name: A quick brown fox jumps over the lazy dog and runs away award
  date: 2021
