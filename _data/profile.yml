primary_name: "Yujie Wang | 王驭捷"
# secondary_name: "王驭捷"
navbar_name: "Yujie Wang | 王驭捷"

positions:
- logo: /assets/images/badges/PKU.png  # Logo is optional
  name: A fourth-year Ph.D. candidate in <a href="https://english.pku.edu.cn/" target="_blank">Peking University (PKU)</a>
# - name: Position 2 without logo


email: "alfredwang@pku.edu.cn"
# cv_link: link-to-your-cv-file
gscholar: nksk9D8AAAAJ  # This is an example, replace it with your own Google Scholar ID
github: AFDWang
# twitter: your_twitter_id  # Do not include the '@' symbol
# wechat_qrcode: /assets/images/etc/wechat.jpg
# wechat_prompt: >-
#   Please tell me your <strong>name</strong> and <strong>affiliation</strong> (current or past) when adding my wechat. Thanks!
# linkedin: your-linked-in-id
orcid: 0009-0000-8375-493X

short_bio_text_justify: false
short_bio: >-
  <p>
    I am a Ph.D. student in the School of Computer Science at <a href="https://english.pku.edu.cn/" target="_blank">Peking University (PKU)</a>, 
    where I have been studying since 2021 under the guidance of <a href="https://cuibinpku.github.io/" target="_blank">Prof. Bin Cui</a>.
    I received my Bachelor's degree from Peking University in 2021.
  </p>
  <p>
    My research interest primarily lies in <strong>Distributed Deep/Machine Learning (DL/ML) Systems, Infrastructure for Large Language Models (LLMs)</strong>.
    Currently, I am focusing on: (1) Parallelism optimization for LLMs training; (2) Efficient long-context training; (3) Multi-task, multi-modality training acceleration; 
    (4) Memory management and communication optimization in distributed systems.
    Recently, I am also exploring: (1) Diffusion model training and inference optimization, and (2) Post-training and reinforcement learning techniques.
  </p>
  <p>
    I have published 9 papers in top-tier CCF-A conferences and journals (4 first-authored and 2 second-authored), including ASPLOS, TKDE, ICLR, VLDB, SOSP, SIGMOD and SIGKDD.
    I am the designer, project leader, and main developer of <a href="https://github.com/PKU-DAIR/Hetu-Galvatron" target="_blank">Hetu-Galvatron</a>, 
    an open-source automatic parallel training system optimized for LLMs. 
    I am also a core developer of <a href="https://github.com/PKU-DAIR/Hetu" target="_blank">Hetu</a>, a high-performance distributed deep learning system. 
  </p>
  <p>
    My works and systems has been applied in billion-scale industrial applications, such as accelerating the training of LLMs with over 100B parameters, 
    and has been utilized by companies like HUAWEI, ZTE, Alibaba, and etc. 
    Currently, I am also collaborating with more industrial companies to deploy and further develop these systems, such as ByteDance and Baidu.
  </p>

portrait_url: /assets/images/photos/portrait-wyj.jpg
# portrait_caption: >-
#   Photo by Manja Vitolic on Unsplash (this caption is optional, comment it out to disable).

education:
- name: Peking University
  logo: /assets/images/badges/PKU.png
  position: >- 
    School of Computer Science <br/>
    Ph.D. Candidate, advised by Prof. Bin Cui
  date: 2021 - present
- name: Peking University
  logo: /assets/images/badges/PKU.png
  position: B.Sc (Bachelor of Science) in Computer Science and Technology
  date: 2017 - 2021

experience:
- name: Hetu Team, PKU-DAIR (Data and Intelligence Research Lab), Peking University
  logo: /assets/images/badges/hetu.png
  position: System Researcher # Project leader of Hetu-Galvatron, an open-source LLM automatic parallel training system; Core developer of Hetu, a high-performance distributed DL system.
  date: 2019 - present

# Project leader of <a href="https://github.com/PKU-DAIR/Hetu-Galvatron" target="_blank">Hetu-Galvatron</a>, an open-source LLM automatic parallel training system; Core developer of <a href="https://github.com/PKU-DAIR/Hetu" target="_blank">Hetu</a>, a a high-performance distributed DL system.

- name: ByteDance, Seed Group - CV - AI Platform
  logo: /assets/images/badges/bytedance.png
  position: System Research Intern # Development of scalable and robust LLMs training infrastructure, e.g., efficient long-context training system, FlexSP.
  date: 2025 - present

- name: Alibaba Cloud, Platform of Artificial Intelligence (PAI)
  logo: /assets/images/badges/BABA.png
  position: System Research Intern # Design and development of efficient large-scale multi-task multi-modality model training system, Spindle.
  date: 2023 - 2024

# - name: Beijing Academy of Artificial Intelligence (BAAI)
#   logo: /assets/images/badges/Baai.png
#   position: System Research Intern
#   date: 2023

awards:
- name: Peking University Merit Student              北京大学三好学生
  date: 2024
- name: Peking University Xiaomi Scholarship         北京大学小米奖学金
  date: 2023
- name: Peking University Merit Student              北京大学三好学生
  date: 2023
- name: Peking University Outstanding Graduate       北京大学优秀毕业生
  date: 2021
- name: Peking University Second-class Scholarship   北京大学二等奖学金
  date: 2020
- name: Peking University Merit Student              北京大学三好学生
  date: 2020
- name: Peking University Golden Arowana Scholarship 北京大学金龙鱼奖学金
  date: 2019
- name: Peking University Merit Student              北京大学三好学生
  date: 2019
- name: Peking University Founder Scholarship        北京大学方正奖学金
  date: 2018
- name: Peking University Merit Student              北京大学三好学生
  date: 2018
